{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRyzNHtiqZQI",
        "outputId": "d93d2ab1-0cad-43db-add1-74a31629bb0e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68yLYK0Cqx53",
        "outputId": "ecdae19d-b2a4-447b-ab68-057355f78d39"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3dlGqjMpvoU",
        "outputId": "cc3b5c84-c160-413a-c92e-22564b4a411c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'I', 'am', 'Tushar', '&', 'I', 'love', 'playing', 'and', 'dancing']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "sentence = \"Hello, I am Tushar & I love playing and dancing\"\n",
        "tokens = word_tokenize(sentence)\n",
        "print(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lowercase_words = []\n",
        "for word in tokens:\n",
        "   word = word.lower()\n",
        "   lowercase_words.append(word)\n",
        "\n",
        "print(lowercase_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcVmHab3qE9g",
        "outputId": "431fbf27-c25b-4486-a6c7-beba3c3e9745"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', ',', 'i', 'am', 'tushar', '&', 'i', 'love', 'playing', 'and', 'dancing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "for word in lowercase_words:\n",
        "    tokens = ps.stem(word)\n",
        "    print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO90OwSGq4TE",
        "outputId": "69e4f032-0960-4408-95d5-703c811b7423"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            ",\n",
            "i\n",
            "am\n",
            "tushar\n",
            "&\n",
            "i\n",
            "love\n",
            "play\n",
            "and\n",
            "danc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wml = WordNetLemmatizer()\n",
        "lemma = []\n",
        "for word in lowercase_words:\n",
        "    tokens = wml.lemmatize(word)\n",
        "    lemma.append(tokens)\n",
        "    print(tokens)"
      ],
      "metadata": {
        "id": "wURDd74XrNoy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d90b528-8c33-4bac-b99f-11ae88f7873c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            ",\n",
            "i\n",
            "am\n",
            "tushar\n",
            "&\n",
            "i\n",
            "love\n",
            "playing\n",
            "and\n",
            "dancing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "ZRgjTO1qrlbc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_words = []\n",
        "Stopwords = set(stopwords.words('english'))\n",
        "for word in lemma:\n",
        "    if word not in Stopwords:\n",
        "         filter_words.append(word)\n",
        "         print(word)"
      ],
      "metadata": {
        "id": "IRv0c8myrVQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f84698e7-c014-4401-adec-580d3de1fde8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            ",\n",
            "tushar\n",
            "&\n",
            "love\n",
            "playing\n",
            "dancing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WaOI4kN7rhCT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pFBsgM0kr99f"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}